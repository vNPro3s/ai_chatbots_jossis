{"cells":[{"cell_type":"markdown","id":"a786c77c","metadata":{"id":"a786c77c"},"source":["# LangChain: Memory\n","\n","## Outline\n","* ConversationBufferMemory\n","* ConversationBufferWindowMemory\n","* ConversationTokenBufferMemory\n","* ConversationSummaryMemory"]},{"cell_type":"code","source":["!pip install python-dotenv\n","!pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"04v54iQSYiXq","executionInfo":{"status":"ok","timestamp":1693741760300,"user_tz":-120,"elapsed":13065,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"61afe0c7-f316-425e-b4ae-b4558abe7106"},"id":"04v54iQSYiXq","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-dotenv\n","  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n","Installing collected packages: python-dotenv\n","Successfully installed python-dotenv-1.0.0\n","Collecting openai\n","  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n","Installing collected packages: openai\n","Successfully installed openai-0.28.0\n"]}]},{"cell_type":"markdown","id":"1297dcd5","metadata":{"id":"1297dcd5"},"source":["## ConversationBufferMemory"]},{"cell_type":"code","source":["import os\n","os.environ['OPENAI_API_KEY'] = 'sk-'"],"metadata":{"id":"X91BUGru36jM","executionInfo":{"status":"ok","timestamp":1693741764824,"user_tz":-120,"elapsed":3,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"id":"X91BUGru36jM","execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"id":"a1f518f5","metadata":{"height":132,"tags":[],"id":"a1f518f5","executionInfo":{"status":"ok","timestamp":1693741769128,"user_tz":-120,"elapsed":470,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e7342d41-1879-46d7-baa9-717aace44ec4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Key length is wrong, only 3 characters\n","Searching for \"mykey\" file\n","Key successfully acquired.\n"]}],"source":["import os\n","import openai\n","from dotenv import load_dotenv\n","\n","try:\n","    # Check if OPENAI_API_KEY is already set and has 51 characters\n","    if 'OPENAI_API_KEY' in os.environ:\n","        if len(os.environ['OPENAI_API_KEY']) == 51:\n","            openai.api_key = os.environ['OPENAI_API_KEY']\n","            print(\"Key successfully acquired.\")\n","        else:\n","            print(f\"Key length is wrong, only {len(os.environ['OPENAI_API_KEY'])} characters\")\n","            print(\"Searching for \\\"mykey\\\" file\")\n","            # Load environment variables from \"mykey\" file\n","            load_status = load_dotenv(\"mykey\", override=True)\n","\n","            # Check if the .env file was successfully loaded\n","            if not load_status:\n","                raise EnvironmentError(\"Could not load the \\\"mykey\\\" file\")\n","\n","            # Retrieve the API key from environment variables\n","            openai.api_key = os.environ['OPENAI_API_KEY']\n","\n","            # Check if the loaded API key has 51 characters\n","            if len(openai.api_key) != 51:\n","                raise ValueError(\"The API key must contain 51 characters\")\n","            print(\"Key successfully acquired.\")\n","    else:\n","        print(\"OPENAI_API_KEY is not set in environment variables.\")\n","\n","except KeyError:\n","    print(\"Error: OPENAI_API_KEY not found in environment variables.\")\n","\n","except EnvironmentError as env_err:\n","    print(f\"Environment Error: {env_err}\")\n","\n","except ValueError as val_err:\n","    print(f\"Value Error: {val_err}\")\n","\n","except Exception as e:\n","    print(f\"An unexpected error occurred: {e}\")"]},{"cell_type":"markdown","id":"2301270b-7a69-40f8-9934-f840499b6ae9","metadata":{"id":"2301270b-7a69-40f8-9934-f840499b6ae9"},"source":["Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the video."]},{"cell_type":"code","source":["# Import the 'pprint' function from the 'pprint' module for pretty-printing Python objects\n","from pprint import pprint"],"metadata":{"id":"mk9V35uD4MOa","executionInfo":{"status":"ok","timestamp":1693741796535,"user_tz":-120,"elapsed":377,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"id":"mk9V35uD4MOa","execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":4,"id":"ce0924a2-ce2d-44ba-a806-c1195720c237","metadata":{"height":234,"id":"ce0924a2-ce2d-44ba-a806-c1195720c237","executionInfo":{"status":"ok","timestamp":1693741775562,"user_tz":-120,"elapsed":381,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"outputs":[],"source":["llm_model = \"gpt-3.5-turbo\""]},{"cell_type":"code","source":["!pip install --upgrade langchain"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5VLRi9kDYpbO","executionInfo":{"status":"ok","timestamp":1693741785437,"user_tz":-120,"elapsed":8107,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"eb503083-c1a9-4a32-df10-8a32459ebb4a"},"id":"5VLRi9kDYpbO","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain\n","  Downloading langchain-0.0.279-py3-none-any.whl (1.6 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.20)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n","Collecting langsmith<0.1.0,>=0.0.21 (from langchain)\n","  Downloading langsmith-0.0.33-py3-none-any.whl (36 kB)\n","Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.2.1)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.5.0)\n","Requirement already satisfied: pydantic-core==2.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.6.1)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, marshmallow, typing-inspect, langsmith, dataclasses-json, langchain\n","Successfully installed dataclasses-json-0.5.14 langchain-0.0.279 langsmith-0.0.33 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"]}]},{"cell_type":"code","execution_count":7,"id":"20ad6fe2","metadata":{"height":81,"tags":[],"id":"20ad6fe2","executionInfo":{"status":"ok","timestamp":1693741805174,"user_tz":-120,"elapsed":4013,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"outputs":[],"source":["from langchain.chat_models import ChatOpenAI\n","from langchain.chains import ConversationChain\n","from langchain.memory import ConversationBufferMemory\n"]},{"cell_type":"code","execution_count":8,"id":"88bdf13d","metadata":{"height":132,"tags":[],"id":"88bdf13d","executionInfo":{"status":"ok","timestamp":1693741808140,"user_tz":-120,"elapsed":405,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"outputs":[],"source":["llm = ChatOpenAI(temperature=0.0, model=llm_model)\n","memory = ConversationBufferMemory()\n","conversation = ConversationChain(\n","    llm=llm,\n","    memory = memory,\n","    verbose=True\n",")"]},{"cell_type":"code","execution_count":9,"id":"db24677d","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":264},"id":"db24677d","executionInfo":{"status":"ok","timestamp":1693741822913,"user_tz":-120,"elapsed":1306,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"4fe15171-2a88-45f2-abce-cfab27637d36"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: Hi, my name is Frank\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\"Hello Frank! It's nice to meet you. How can I assist you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}],"source":["conversation.predict(input=\"Hi, my name is Frank\")"]},{"cell_type":"code","execution_count":10,"id":"cc3ef937","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"cc3ef937","executionInfo":{"status":"ok","timestamp":1693741826272,"user_tz":-120,"elapsed":927,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"f3349cd7-7764-45e6-dda9-d6e5691b3a2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hi, my name is Frank\n","AI: Hello Frank! It's nice to meet you. How can I assist you today?\n","Human: What is 1+1?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'1+1 is equal to 2.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}],"source":["conversation.predict(input=\"What is 1+1?\")"]},{"cell_type":"code","execution_count":11,"id":"acf3339a","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":316},"id":"acf3339a","executionInfo":{"status":"ok","timestamp":1693741830066,"user_tz":-120,"elapsed":911,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"c9f23ea7-2aea-4b26-e128-fa6b6e6ab52a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hi, my name is Frank\n","AI: Hello Frank! It's nice to meet you. How can I assist you today?\n","Human: What is 1+1?\n","AI: 1+1 is equal to 2.\n","Human: What is my name?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'Your name is Frank.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}],"source":["conversation.predict(input=\"What is my name?\")"]},{"cell_type":"code","execution_count":14,"id":"2529400d","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"2529400d","executionInfo":{"status":"ok","timestamp":1693741842868,"user_tz":-120,"elapsed":3,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"c3331cd2-0e24-4056-aa13-dd68adf2ba89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Human: Hi, my name is Frank\n","AI: Hello Frank! It's nice to meet you. How can I assist you today?\n","Human: What is 1+1?\n","AI: 1+1 is equal to 2.\n","Human: What is my name?\n","AI: Your name is Frank.\n"]}],"source":["print(memory.buffer)"]},{"cell_type":"code","execution_count":15,"id":"5018cb0a","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"5018cb0a","executionInfo":{"status":"ok","timestamp":1693741845520,"user_tz":-120,"elapsed":400,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"4f27c9f6-769a-4f95-f290-d3190f281319"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"Human: Hi, my name is Frank\\nAI: Hello Frank! It's nice to meet you. How can I assist you today?\\nHuman: What is 1+1?\\nAI: 1+1 is equal to 2.\\nHuman: What is my name?\\nAI: Your name is Frank.\"}"]},"metadata":{},"execution_count":15}],"source":["memory.load_memory_variables({})"]},{"cell_type":"code","execution_count":16,"id":"14219b70","metadata":{"height":30,"tags":[],"id":"14219b70","executionInfo":{"status":"ok","timestamp":1693741848686,"user_tz":-120,"elapsed":354,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"outputs":[],"source":["memory = ConversationBufferMemory()"]},{"cell_type":"code","execution_count":17,"id":"a36e9905","metadata":{"height":47,"tags":[],"id":"a36e9905","executionInfo":{"status":"ok","timestamp":1693741850328,"user_tz":-120,"elapsed":3,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"outputs":[],"source":["memory.save_context({\"input\": \"Hi\"},\n","                    {\"output\": \"What's up\"})"]},{"cell_type":"code","execution_count":18,"id":"61631b1f","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"61631b1f","executionInfo":{"status":"ok","timestamp":1693741851579,"user_tz":-120,"elapsed":6,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"2e989efb-73d4-4e74-fad5-dbfc1abfb92e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Human: Hi\n","AI: What's up\n"]}],"source":["print(memory.buffer)"]},{"cell_type":"code","execution_count":19,"id":"a2fdf9ec","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"a2fdf9ec","executionInfo":{"status":"ok","timestamp":1693741854824,"user_tz":-120,"elapsed":3,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"85879e65-4f07-4768-b1d5-e22e6d329685"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"Human: Hi\\nAI: What's up\"}"]},"metadata":{},"execution_count":19}],"source":["memory.load_memory_variables({})"]},{"cell_type":"code","execution_count":20,"id":"7ca79256","metadata":{"height":47,"tags":[],"id":"7ca79256","executionInfo":{"status":"ok","timestamp":1693741856470,"user_tz":-120,"elapsed":398,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"outputs":[],"source":["memory.save_context({\"input\": \"Not much, just hanging\"},\n","                    {\"output\": \"Cool\"})"]},{"cell_type":"code","execution_count":21,"id":"890a4497","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"890a4497","executionInfo":{"status":"ok","timestamp":1693741857955,"user_tz":-120,"elapsed":2,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"a3daba08-3595-4f46-d485-be1b1fe1f647"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"]},"metadata":{},"execution_count":21}],"source":["memory.load_memory_variables({})"]},{"cell_type":"markdown","id":"cf98e9ff","metadata":{"tags":[],"id":"cf98e9ff"},"source":["## ConversationBufferWindowMemory"]},{"cell_type":"code","execution_count":22,"id":"66eeccc3","metadata":{"height":30,"tags":[],"id":"66eeccc3","executionInfo":{"status":"ok","timestamp":1693741862107,"user_tz":-120,"elapsed":425,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"outputs":[],"source":["from langchain.memory import ConversationBufferWindowMemory"]},{"cell_type":"code","execution_count":23,"id":"3ea6233e","metadata":{"height":30,"tags":[],"id":"3ea6233e","executionInfo":{"status":"ok","timestamp":1693741864845,"user_tz":-120,"elapsed":377,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"outputs":[],"source":["memory = ConversationBufferWindowMemory(k=1)"]},{"cell_type":"code","execution_count":24,"id":"dc4553fb","metadata":{"height":98,"tags":[],"id":"dc4553fb","executionInfo":{"status":"ok","timestamp":1693741866087,"user_tz":-120,"elapsed":3,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"outputs":[],"source":["memory.save_context({\"input\": \"Hi\"},\n","                    {\"output\": \"What's up\"})\n","memory.save_context({\"input\": \"Not much, just hanging\"},\n","                    {\"output\": \"Cool\"})\n"]},{"cell_type":"code","execution_count":25,"id":"6a788403","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"6a788403","executionInfo":{"status":"ok","timestamp":1693741868798,"user_tz":-120,"elapsed":349,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"d897e363-ce4f-46c6-e248-8d57385207fd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'Human: Not much, just hanging\\nAI: Cool'}"]},"metadata":{},"execution_count":25}],"source":["memory.load_memory_variables({})"]},{"cell_type":"code","execution_count":26,"id":"4087bc87","metadata":{"height":132,"tags":[],"id":"4087bc87","executionInfo":{"status":"ok","timestamp":1693741874727,"user_tz":-120,"elapsed":397,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"outputs":[],"source":["llm = ChatOpenAI(temperature=0.0, model=llm_model)\n","memory = ConversationBufferWindowMemory(k=1)\n","conversation = ConversationChain(\n","    llm=llm,\n","    memory = memory,\n","    verbose=False\n",")"]},{"cell_type":"code","execution_count":27,"id":"4faaa952","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"4faaa952","executionInfo":{"status":"ok","timestamp":1693741876828,"user_tz":-120,"elapsed":896,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"97e76aeb-ab8c-49d5-f13d-62bf77b97808"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Hello Frank! It's nice to meet you. How can I assist you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":27}],"source":["conversation.predict(input=\"Hi, my name is Frank\")"]},{"cell_type":"code","execution_count":28,"id":"bb20ddaa","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"bb20ddaa","executionInfo":{"status":"ok","timestamp":1693741879308,"user_tz":-120,"elapsed":507,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"a481a735-b40c-4dc4-cc35-10fb0e9a4956"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1+1 is equal to 2.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}],"source":["conversation.predict(input=\"What is 1+1?\")"]},{"cell_type":"code","execution_count":29,"id":"489b2194","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"489b2194","executionInfo":{"status":"ok","timestamp":1693741882598,"user_tz":-120,"elapsed":1550,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"e6cb98f6-771f-4aef-d081-764a5ccef398"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}],"source":["conversation.predict(input=\"What is my name?\")"]},{"cell_type":"markdown","id":"d2931b92","metadata":{"id":"d2931b92"},"source":["## ConversationTokenBufferMemory"]},{"cell_type":"code","execution_count":30,"id":"9f6d063c","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"9f6d063c","executionInfo":{"status":"ok","timestamp":1693741894901,"user_tz":-120,"elapsed":7493,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"2063b0a6-77ca-41ff-f068-4bdd382018bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tiktoken\n","  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n","Installing collected packages: tiktoken\n","Successfully installed tiktoken-0.4.0\n"]}],"source":["!pip install tiktoken"]},{"cell_type":"code","execution_count":31,"id":"fb9020ed","metadata":{"height":64,"tags":[],"id":"fb9020ed","executionInfo":{"status":"ok","timestamp":1693741900099,"user_tz":-120,"elapsed":376,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"outputs":[],"source":["from langchain.memory import ConversationTokenBufferMemory\n","from langchain.llms import OpenAI\n","llm = ChatOpenAI(temperature=0.0, model=llm_model)"]},{"cell_type":"code","execution_count":32,"id":"43582ee6","metadata":{"height":132,"tags":[],"id":"43582ee6","executionInfo":{"status":"ok","timestamp":1693741926002,"user_tz":-120,"elapsed":3214,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"outputs":[],"source":["memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n","memory.save_context({\"input\": \"AI is what?!\"},\n","                    {\"output\": \"Amazing!\"})\n","memory.save_context({\"input\": \"Backpropagation is what?\"},\n","                    {\"output\": \"Beautiful!\"})\n","memory.save_context({\"input\": \"Chatbots are what?\"},\n","                    {\"output\": \"Charming!\"})"]},{"cell_type":"code","execution_count":33,"id":"284288e1","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"284288e1","executionInfo":{"status":"ok","timestamp":1693741928683,"user_tz":-120,"elapsed":379,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"9c5c9598-97a5-41fc-9819-ab1929fade2c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'AI: Amazing!\\nHuman: Backpropagation is what?\\nAI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"]},"metadata":{},"execution_count":33}],"source":["memory.load_memory_variables({})"]},{"cell_type":"markdown","id":"5ff55d5d","metadata":{"id":"5ff55d5d"},"source":["## ConversationSummaryMemory"]},{"cell_type":"code","execution_count":34,"id":"72dcf8b1","metadata":{"height":30,"tags":[],"id":"72dcf8b1","executionInfo":{"status":"ok","timestamp":1693741931169,"user_tz":-120,"elapsed":3,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"outputs":[],"source":["from langchain.memory import ConversationSummaryBufferMemory"]},{"cell_type":"code","execution_count":35,"id":"4a5b238f","metadata":{"height":268,"tags":[],"id":"4a5b238f","executionInfo":{"status":"ok","timestamp":1693741935740,"user_tz":-120,"elapsed":3082,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"outputs":[],"source":["# create a long string\n","schedule = \"There is a meeting at 8am with your product team. \\\n","You will need your powerpoint presentation prepared. \\\n","9am-12pm have time to work on your LangChain \\\n","project which will go quickly because Langchain is such a powerful tool. \\\n","At Noon, lunch at the italian resturant with a customer who is driving \\\n","from over an hour away to meet you to understand the latest in AI. \\\n","Be sure to bring your laptop to show the latest LLM demo.\"\n","\n","memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n","memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n","memory.save_context({\"input\": \"Not much, just hanging\"},\n","                    {\"output\": \"Cool\"})\n","memory.save_context({\"input\": \"What is on the schedule today?\"},\n","                    {\"output\": f\"{schedule}\"})"]},{"cell_type":"code","execution_count":36,"id":"2e4ecabe","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"2e4ecabe","executionInfo":{"status":"ok","timestamp":1693741937020,"user_tz":-120,"elapsed":2,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"b3132e1c-4d6b-4559-fd39-d11b52ac25e2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting.'}"]},"metadata":{},"execution_count":36}],"source":["memory.load_memory_variables({})"]},{"cell_type":"code","execution_count":37,"id":"6728edba","metadata":{"height":98,"tags":[],"id":"6728edba","executionInfo":{"status":"ok","timestamp":1693741938713,"user_tz":-120,"elapsed":1,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}}},"outputs":[],"source":["conversation = ConversationChain(\n","    llm=llm,\n","    memory = memory,\n","    verbose=True\n",")"]},{"cell_type":"code","execution_count":38,"id":"9a221b1d","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"9a221b1d","executionInfo":{"status":"ok","timestamp":1693741950791,"user_tz":-120,"elapsed":9892,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"a83c0bf7-e2c6-486d-8bf5-6ef156b12892"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting.\n","Human: What would be a good demo to show?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\"A good demo to show during the lunch meeting with the customer interested in AI would be the latest LLM (Language Model) demo. The LLM is a cutting-edge AI model that can generate human-like text based on a given prompt. It has been trained on a vast amount of data and can generate coherent and contextually relevant responses. By showcasing the LLM demo, you can demonstrate the capabilities of AI in natural language processing and generate interest in potential applications for the customer's business.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":38}],"source":["conversation.predict(input=\"What would be a good demo to show?\")"]},{"cell_type":"code","execution_count":39,"id":"bb582617","metadata":{"height":30,"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"bb582617","executionInfo":{"status":"ok","timestamp":1693741950792,"user_tz":-120,"elapsed":6,"user":{"displayName":"Siegfried Handschuh","userId":"12280498604816269989"}},"outputId":"2f18ed3f-0236-4a9f-8565-b4ed268134ca"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"System: The human and AI exchange greetings and discuss the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting. The human asks what would be a good demo to show, and the AI suggests showcasing the latest LLM (Language Model) demo. The LLM is a cutting-edge AI model that can generate human-like text based on a given prompt. By showcasing the LLM demo, the AI can demonstrate the capabilities of AI in natural language processing and generate interest in potential applications for the customer's business.\"}"]},"metadata":{},"execution_count":39}],"source":["memory.load_memory_variables({})"]},{"cell_type":"markdown","id":"c6709b89-182e-4b7b-b811-1584dda20652","metadata":{"id":"c6709b89-182e-4b7b-b811-1584dda20652"},"source":["Reminder: Download your notebook to you local computer to save your work."]},{"cell_type":"code","execution_count":null,"id":"4ba827aa","metadata":{"height":30,"id":"4ba827aa"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"2c07922b","metadata":{"height":30,"id":"2c07922b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"52696c8c","metadata":{"height":30,"id":"52696c8c"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"48690d13","metadata":{"height":30,"id":"48690d13"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"85bba1f8","metadata":{"height":30,"id":"85bba1f8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"96a62e89","metadata":{"height":30,"id":"96a62e89"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"f953ad8d","metadata":{"height":30,"id":"f953ad8d"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b9bb2617","metadata":{"height":30,"id":"b9bb2617"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"be1989bf","metadata":{"height":30,"id":"be1989bf"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b1f8dca6","metadata":{"height":30,"id":"b1f8dca6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"e9120949","metadata":{"height":30,"id":"e9120949"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"55849fb5","metadata":{"height":30,"id":"55849fb5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"94ae491b","metadata":{"height":30,"id":"94ae491b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"e7c3aec3","metadata":{"height":30,"id":"e7c3aec3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"5ae51a3f","metadata":{"height":30,"id":"5ae51a3f"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"06894001","metadata":{"height":30,"id":"06894001"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"e2fb674c","metadata":{"height":30,"id":"e2fb674c"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"5158f4c8","metadata":{"height":30,"id":"5158f4c8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"2cebe066","metadata":{"height":30,"id":"2cebe066"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"65caee4d","metadata":{"height":30,"id":"65caee4d"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"04799230","metadata":{"height":30,"id":"04799230"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"30795c10","metadata":{"height":30,"id":"30795c10"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"08ed59c4","metadata":{"height":30,"id":"08ed59c4"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"bb43eee3","metadata":{"height":30,"id":"bb43eee3"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}